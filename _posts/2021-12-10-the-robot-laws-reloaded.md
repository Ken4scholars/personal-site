---
layout: post
section-type: post
title: "The Robot Laws: Reloaded"
category: sci-fi 
tags: [ 'sci-fi', 'robots', 'AI', 'future']
---

First of all, let me tell you - I do not like to wake up early. In the rare occasions when I do, it is usually out of a great
necessity. You may wonder what those necessities are, like say, for work? But that is a topic for another day.

Given the premise above, you can understand how grave the situation was when I suddenly got up by 6 AM one morning 
a few months ago, from a bad dream. And what a nightmare it was. Honestly, the details have escaped my memories, but 
believe me, it was horrible, oh that I know for sure! The only detail I do recall is that this horrible event was orchestrated by robots, yes, robots!

This nightmare so alarmed me that my mind went straight to search for solutions to curb the excesses of these pesky angry supervillain 
robots before I could go back to sleep. And think up solutions I did. I even wrote down these solutions before going back to sleep. 
When I woke up later, it seemed like the whole thing was all a dream, but my notes bore witness to the event and convinced me that it was real after all.

Before diving into the solutions that flooded my mind, lets dive back into the world of <a href="https://en.wikipedia.org/wiki/Isaac_Asimov" target="\_blank">Isaac Asimov</a> 
and the original robot laws. Isaac Asimov is one of the most popular sci-fi authors of the 20th century and the author of the 
<a href="https://en.wikipedia.org/wiki/Foundation_series" target="\_blank">Foundation novel series</a>.
By the way, for Asimov's fans, _Foundation_ recently got a <a href="https://tv.apple.com/us/show/foundation/umc.cmc.5983fipzqbicvrve6jdfep4x3" target="\_blank">TV series</a>
which is unfortunately currently only available in Apple TV+.

## The original laws
At first, there were three laws as follows:
1.  A robot may not injure a human being or, through inaction, allow a human being to come to harm
2.  A robot must obey the orders given it by human beings except where such orders would conflict with the First Law
3.  A robot must protect its own existence as long as such protection does not conflict with the First or Second Laws

There are several issues with these laws that have sparked lots of conversations. To start with, they are ambiguous and difficult to
program into robots, atleast considering the technology of today. Secondly, the laws often clash with each other, for example, what if protecting
a person requires harming another? There are other issues with these laws which have been discussed in 
<a href="https://theconversation.com/after-75-years-isaac-asimovs-three-laws-of-robotics-need-updating-74501" target="\_blank">this article on _The Conversation_ blog</a>.

The loopholes in the laws are often seen in the works of Asimov himself that he had to come up with a zeroth law:
* A robot may not harm humanity, or, by inaction, allow humanity to come to harm.

This zeroth law which supersedes the other laws is even more ambiguous. What do we regard as humanity? Would it be okay to kill all the criminals to keep humanity safe?
Would it be okay to keep humanity _uncomfortable_ just to ensure it is _safe_? This is exactly what the robots in _I, Robot_ did: they created an oppressive state that ensured minimal _collective_ harm 
to the society but that obviously was very uncomfortable for humans and takes away some of our freedoms and choices. As a matter of fact, humans sometimes if not most,
prefer freedom of choice to protection as is examplified in the new  liberal movement. A common theme seen in _The Matrix_ and other works, is when robots decide that humans are harmful to themselves and would be much happier in a fake virtual _utopia_
where they live almost programmed lives. The zeroth law while ambitious, gives a lot of power to the robots which essentially allows them ignore the rest of the laws and take the fate of humanity into their hands.

## The new laws

The quick solutions that came to my mind on that fateful morning tries to curb the excesses of the robots under the zeroth law while also taking our current technological realities into consideration.

The laws are:
1.  A single robot should not be in stronger in fighting power than an average human.
2.  A single robot should not be allowed to communicate or seek reinforcement from more than _n_ robots(_n_ can be determined based on the situation but a good default can be 20).
3.  A robot-to-robot message cannot be propagated more than _m_ times to avoid more reinforcements(_m_ can be set to 2 for a start).
4.  A single robot can only make _r_ number of other robots(_r_ can also be set to 2).

Notice how these laws are much lower level and less ambiguous than the original laws and should be simpler to program into the robots. 
The premise is that robots can easily be mass-produced unlike humans and that gives them more destructive power in the event of them going rogue. Even Elon Musk, who has been a strong proponent of robots and AI posing 
a threat to humanity, recently announced that Tesla will develop a humanoid robot, however, to protect against the robot going rogue, it will be weaker than humans. While this is a good step, it does not solve the problem if a large number of such robots are in service.
This is shown in the episode _Automated Customer Service_, in the second installment of the Netflix _Love, Death  & Robots_ series. 

These laws effectively limit the fighting power of each individual robot and their power as a group. Breaking the line of communication between them in this way, will help mitigate their advantage of numbers.

Come to think of it, I just realised I had the dream just after Elon made his announcement of the Tesla humanoid robot! But of course! Elon was our last line of defence against these human-hating-but-most-times-useful beings!

Of course these laws introduces some limits that may lower the efficiency of robots such as the ability of self-driving cars to communicate and coordinate their navigation, so there is a tradeoff. I acknowledged that even in my
half-asleep state while scribing the laws in my notebook. So we will have to figure out a away to balance the tradeoffs especially by varying the parameters in the laws.

Phew! Now we can all have a good sleep knowing our grandkids will be safe from these _evil_ beings (are they though?).